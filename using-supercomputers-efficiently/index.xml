<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Using Supercomputers Efficiently on Introduction to Parallelism and Supercomputing Workflows</title><link>/using-supercomputers-efficiently/</link><description>Recent content in Using Supercomputers Efficiently on Introduction to Parallelism and Supercomputing Workflows</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 24 Nov 2022 23:35:07 +0800</lastBuildDate><atom:link href="/using-supercomputers-efficiently/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Latency and Bottleknecks</title><link>/using-supercomputers-efficiently/data-latency-and-bottlenecks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/using-supercomputers-efficiently/data-latency-and-bottlenecks/</guid><description>Data Latency is the time taken to transfer data to a processor (a core in a CPU or GPU).
Data Location Average Latency Normalised Human Time 3 GHz CPU Clock Cycle 0.3. ns 1 s CPU Cache 0.9-28 ns 2 s - 1 min RAM 70-100 ns 3.5-5.5 min Solid State Disk (NVME) 7-150 µs 2 hrs to 2 days Hard Disk Drive 1-10 µs 11 days to 4 months Another Supercomputing Node 100-1000 ms 3-30 years Depending on the type of work you are doing, the amount of data you are working and the type of system you are working on, your work will be:</description></item><item><title>Case Study - Alice</title><link>/using-supercomputers-efficiently/case-study-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/using-supercomputers-efficiently/case-study-1/</guid><description>Alice is working on an astrophysics project that explores how light (photons) are scattered in stellar atmospheres. She is using Monte Carlo Simulation, which simulates the path of 10000s of individual photons based on randomised starting conditions and events. As the path of each simulated independently from the other, this part of her work is embarrassingly parallel. She uses MPI on Setonix to simulate one photon per CPU core. As each of Alice&amp;rsquo;s simulations completes quickly, saving the result of each simulation would result in her work being Memory bound.</description></item><item><title>Case Study - Bob</title><link>/using-supercomputers-efficiently/case-study-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/using-supercomputers-efficiently/case-study-2/</guid><description>Bob is working on a computer-vision project that is a machine learning project. He is tasked with training a neural network on a large dataset. Bob is working on Topaz as GPUs excel at performing the mathematical operations used in machine learning through shared-memory Parallelism. Bob finds that his work is Memory bound as he can fit only a small number of images (&amp;lsquo;batch size&amp;rsquo;) in the VRAM of one GPU on Topaz.</description></item></channel></rss>